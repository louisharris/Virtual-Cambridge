Virtual Cambridge
Virtual world of Cambridge

This project will include:

Unity Base world for world generation with google cardboard
Point cloud mesh generation for the VR environment.
multi-360 image envrironment generation for the VR environment
Speech dialogue integration for NPC interaction within the virtual cambridge:
Speech-to-text via Mozilla DeepSpeech tensorflow deep learning.
Speech-to-text via IBM Watson unity API library.
Speech-to-text via Bing Speech API.
Mansur and Alex's updated speech dialogue model to implement the AI interaction aspect through text generated from speech
Text-to-speech via Microsoft Azure API
Google Cardboard VR App for Android
Week 5 Report:
Personal project:
What has gone wrong

3D object generation proved not useful enough on a large scale. Made it hard to implement condsidering that the VR world is mostly in an outside environment, so there are depth issues.
What I am finding difficult

Using WSL means there are compatibility issues for between the ubuntu subsystem and windows versions of libraries.
Accessing the Bing Speech API using C# for use within unity, having problems currently with getting a .dll file to work within the project library so that I can access the microphone.
What I have done

I've explored many different avenues of proceeding further with this project, and have attempted pretty much all of them, which have all had problems so far. Have gone back to square one. However I have learned a lot from this and will be able to progress faster now.
Mobile development part of the project has gone smoothly, so importing to mobile should not be an issue (unless I have future microphone issues).
What I have learned

Experience with C#, mobile development, unity, photogrammetry methods
What to do next

Get the Microsoft API working and hooked up to mobile app with speaker goal intention implemented. Will be hard to make the dialogue goal oriented, as I will be using an open interaction chatbot system, but my conversation needs to have an end goal (booking a punt tour) Luckily I have a plan.
Create the VR world using multiple 360 photos taken with movement between them.
Augumented reality bot added so be able to converse with within the virtual world.
Hook up Alex and Mansur's speech dialogue system to this bot.
NLP side group project:
What has gone wrong

Nothing yet although we have not progressed far (just sorting some of the file data)
What I am finding difficult

Difficulty with sharing .csv files across github, files sizes are too large, so have left out of the repo (these do not need updating and sharing anyway)
What I have done

Created a simple github repo (https://github.com/louisharris/cognitive-paper-ultimate-attainment) so we can share the jupyter notebook easily between us
What I have learned

Inclusing the ML commando course, I have learned a lot about using python for NLP/Data science processing. Am also more comfortable with using python although have not used much outside of this course
Improved at using Git & using virtual environments for projects to keep the system installations tidy
What to do next

Plot graphs, reproducing the initial article, once sorting the data more and removing unneccessary data entries for testing the hypothesis.
Come to a conclusion as to whether our results agree with the initial article results, and to realise the implications of this.
